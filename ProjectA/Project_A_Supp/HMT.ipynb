{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpFRkPsrSR5Y",
    "outputId": "18f208e6-0c0d-4a10-e32b-5916cd3fb387"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UAHDf7YhShHO"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir(r'/content/drive/My Drive/ECE1512_TA')  # Change the directory to torchRay-master folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RKtE7d0YAG2"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IwBCKBEXVYjN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Flatten\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from tensorflow.core.util import event_pb2\n",
    "from tensorflow.python.lib.io import tf_record\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "calsYefrYC1P"
   },
   "source": [
    "# Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qjubR6-Zvpn2",
    "outputId": "a933f831-e33c-43df-a1ff-448d3c17e5b3"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: '/content/drive/My Drive/ECE1512_TA/hmt_dataset/HMT_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m train_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.\u001b[39m,\n\u001b[0;32m      5\u001b[0m shear_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m      6\u001b[0m rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[0;32m      7\u001b[0m horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      8\u001b[0m vertical_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m test_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbilinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(test_dir,\n\u001b[0;32m     20\u001b[0m class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m),\n\u001b[0;32m     23\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     24\u001b[0m shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\users\\jiaming\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\preprocessing\\image.py:976\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    899\u001b[0m                         directory,\n\u001b[0;32m    900\u001b[0m                         target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m                         subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    912\u001b[0m                         interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    913\u001b[0m   \u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \n\u001b[0;32m    915\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;124;03m          and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 976\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m      \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m      \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\jiaming\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\preprocessing\\image.py:394\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    392\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[0;32m    393\u001b[0m   kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m--> 394\u001b[0m \u001b[38;5;28msuper\u001b[39m(DirectoryIterator, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    395\u001b[0m     directory, image_data_generator,\n\u001b[0;32m    396\u001b[0m     target_size\u001b[38;5;241m=\u001b[39mtarget_size,\n\u001b[0;32m    397\u001b[0m     color_mode\u001b[38;5;241m=\u001b[39mcolor_mode,\n\u001b[0;32m    398\u001b[0m     classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m    399\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39mclass_mode,\n\u001b[0;32m    400\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    401\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m    402\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m    403\u001b[0m     data_format\u001b[38;5;241m=\u001b[39mdata_format,\n\u001b[0;32m    404\u001b[0m     save_to_dir\u001b[38;5;241m=\u001b[39msave_to_dir,\n\u001b[0;32m    405\u001b[0m     save_prefix\u001b[38;5;241m=\u001b[39msave_prefix,\n\u001b[0;32m    406\u001b[0m     save_format\u001b[38;5;241m=\u001b[39msave_format,\n\u001b[0;32m    407\u001b[0m     follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[0;32m    408\u001b[0m     subset\u001b[38;5;241m=\u001b[39msubset,\n\u001b[0;32m    409\u001b[0m     interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\jiaming\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py:115\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    114\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    117\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: '/content/drive/My Drive/ECE1512_TA/hmt_dataset/HMT_train'"
     ]
    }
   ],
   "source": [
    "train_dir = '/content/drive/My Drive/ECE1512_TA/hmt_dataset/HMT_train' #you should change to your directory\n",
    "test_dir = '/content/drive/My Drive/ECE1512_TA/hmt_dataset/HMT_test' #you should change to your directory\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
    "shear_range=0.1,\n",
    "rotation_range=15,\n",
    "horizontal_flip=True,\n",
    "vertical_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "class_mode='categorical',\n",
    "interpolation='bilinear',\n",
    "target_size=(224, 224),\n",
    "batch_size=32,\n",
    "shuffle=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "class_mode='categorical',\n",
    "interpolation='bilinear',\n",
    "target_size=(224, 224),\n",
    "batch_size=32,\n",
    "shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1ewbg_Qv6Gd"
   },
   "source": [
    "Overrided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q-2qXovYJQ6"
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sjj4ZEe4XFCF"
   },
   "outputs": [],
   "source": [
    "weight_decay = 5e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(224, 224, 3), kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# flatten?\n",
    "\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "#model.add(Dense(1024, activation='relu', kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.5),\n",
    "#                bias_initializer=keras.initializers.Zeros(), kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Dense(8, activation='softmax', kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.5),\n",
    "                bias_initializer=keras.initializers.Zeros(), kernel_regularizer=regularizers.l2(weight_decay)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-4ejl671J3v",
    "outputId": "39745770-f8b9-4bbf-c06b-e966c2246968"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kvv6IX1-8n3O"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dD2-9ryQ1RrA"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROz-WKALbiLh"
   },
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch):\n",
    "    base_ep = 15\n",
    "    return 1e-3 * (.5 ** (epoch // base_ep))\n",
    "lr_reduce_cb = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir='log2', write_graph=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=8, min_delta=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2ysz8Bu1PW3"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=train_generator.n // 32,\n",
    "                    epochs=150,\n",
    "                    callbacks=[tensorboard_cb],                  \n",
    "                    shuffle = True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyuUgXy7p63G"
   },
   "outputs": [],
   "source": [
    "model.save('HMT.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHXAMFq68q8p"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBqL38S0KYQp"
   },
   "outputs": [],
   "source": [
    "model=load_model('HMT.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdmpfmFXOvGQ"
   },
   "outputs": [],
   "source": [
    "def my_summary_iterator(path):\n",
    "  for r in tf_record.tf_record_iterator(path):\n",
    "    yield event_pb2.Event.FromString(r)\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "train_lr = []\n",
    "#print('log/train/' + os.listdir('log/train')[2])\n",
    "for e in my_summary_iterator('log/train/' + os.listdir('log/train')[-1]):\n",
    "  for v in e.summary.value:\n",
    "    if v.tag == 'epoch_accuracy':\n",
    "      train_acc.append(v.simple_value)\n",
    "    elif v.tag == 'epoch_loss':\n",
    "      train_loss.append(v.simple_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "ZuYBQxCzktXv",
    "outputId": "9057fcfa-bd59-43a8-839c-ed377d7dedd9"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(train_acc)), train_acc)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training progress: Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "lFYPSLg_lEvC",
    "outputId": "64798f15-5b60-406f-d5bf-584f80f3fed4"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(train_loss)), train_loss)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training progress: Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcPaIZw0-64V"
   },
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6587JG1kysH"
   },
   "source": [
    "Load the explaier library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpr09_NnlIGB"
   },
   "outputs": [],
   "source": [
    "from xai_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPg-zk4vBHYs"
   },
   "source": [
    "Load a batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R54o5-zYdQLk"
   },
   "outputs": [],
   "source": [
    "test_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfBMriHk-9xB"
   },
   "outputs": [],
   "source": [
    "image_batch,label_batch=test_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1NPS8fpBXwj"
   },
   "source": [
    "Classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUCx85IBCOSx"
   },
   "outputs": [],
   "source": [
    "classes=['Tumor', 'Stroma', 'Complex', 'Lympho', 'Debris', 'Mucosa', 'Adiopse', 'Empty']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HJ71p8JDcNf"
   },
   "source": [
    "Predict a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkCRas5iDANo"
   },
   "outputs": [],
   "source": [
    "index=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qeSrbciv_99p",
    "outputId": "6f39654d-fbff-4c22-9497-fd7f46f19cd7"
   },
   "outputs": [],
   "source": [
    "prediction=model(image_batch)\n",
    "print('True label: '+classes[np.argmax(label_batch[index])])\n",
    "print('Predicted_label: '+classes[np.argmax(prediction[index])])\n",
    "print('Confidence score for the correct label: '+str(prediction[index][np.argmax(label_batch[index])].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mv0LV1mV2cW1"
   },
   "source": [
    "Generate explanation map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFnbIyRflKIJ"
   },
   "source": [
    "## SISE (Semantic Input Sampling for Explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0G_a-f2NCSC"
   },
   "source": [
    "Set the layer(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3w_x_NRXNDb9"
   },
   "outputs": [],
   "source": [
    "layers=[['conv2d_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9mgBbiQ_uu4",
    "outputId": "1f0b89ae-fc63-41d9-e237-09ccfe91e8ff"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "explanation_map_SISE = SISE(np.expand_dims(image_batch[index], axis=0), model, layers=layers, class_index=np.argmax(prediction[index]), grad_thr=0.)\n",
    "explanation_map_SISE -= explanation_map_SISE.min()\n",
    "explanation_map_SISE /= explanation_map_SISE.max()+10e-30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i42jHJAMlPxU"
   },
   "source": [
    "## Grad-CAM (Gradient-based Class Activation Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnTEyHwT-8OO",
    "outputId": "130440e0-fee2-4789-cb58-49752976e136"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "explanation_map_GradCAM = grad_cam(model, np.expand_dims(image_batch[index], axis=0), 'max_pooling2d_1')\n",
    "explanation_map_GradCAM -= explanation_map_GradCAM.min()\n",
    "explanation_map_GradCAM /= explanation_map_GradCAM.max()+10e-30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtaAc1QTlX_8"
   },
   "source": [
    "## RISE (Randomized Input Sampling for Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-7V-ug0jlb2d",
    "outputId": "4a693302-0fe3-4931-c994-439cdb37d50e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "explanation_map_RISE = RISE(image_batch[index], model, class_index=np.argmax(prediction[index]) ,N_MASKS=1000)\n",
    "explanation_map_RISE -= explanation_map_RISE.min()\n",
    "explanation_map_RISE /= explanation_map_RISE.max()+10e-30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zJajjz3xtOY"
   },
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "9XyspS_Wlvii",
    "outputId": "068dc375-6800-4bed-9e21-cffab747b340"
   },
   "outputs": [],
   "source": [
    "#@title Plot the results\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(image_batch[index])\n",
    "plt.axis('off')\n",
    "plt.title('Sample image')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(image_batch[index])\n",
    "plt.imshow(explanation_map_SISE, cmap='jet', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.title('Explanation map (SISE)')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(image_batch[index])\n",
    "plt.imshow(explanation_map_GradCAM, cmap='jet', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.title('Explanation map (Grad-CAM)')\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(image_batch[index])\n",
    "plt.imshow(explanation_map_RISE, cmap='jet', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.title('Explanation map (RISE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wngWZcQ92jSL"
   },
   "source": [
    "## Quantitative evaluation of the explanation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmT1TQwnaF_E"
   },
   "outputs": [],
   "source": [
    "def calculate_drop_increase(images, model, exmap, class_index, frac=0.15):\n",
    "    '''\n",
    "    inputs:\n",
    "        images: a 4-D image of size (1 x H x W x 3)\n",
    "          containing an image in RGB format and of size (H x W)\n",
    "        model: The base model\n",
    "        exmap: a given explanation map whose completeness is to be evaluated.\n",
    "        class_index: The class to whom the explanation map is related to.\n",
    "        frac: The fraction of top pixels selected.\n",
    "    returns:v\n",
    "        a tuple with 4 calculates values:\n",
    "        (drop, increase, original_pred, eplanation_pred)\n",
    "        drop (float): drop rate (between 0 and 1)\n",
    "        increase (boolean): \"1\" if increase happened\n",
    "        original_pred: confidence score for original image\n",
    "        explanation_pred:  confidence score for the selected top pixels of the image.\n",
    "    '''\n",
    "    predictions = model.predict(images)\n",
    "    # Pre-processing image \n",
    "    img=images[0,:,:,:]\n",
    "    img=img_to_array(img)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    # Getting the prediction for image\n",
    "    Y=predictions[0][class_index]\n",
    "    \n",
    "    grad_array=np.reshape(exmap, (-1,))\n",
    "    array_size=int(grad_array.shape[0]*frac)\n",
    "    thr=np.flip(sorted(grad_array))[array_size]\n",
    "    exmap1_msk=(exmap>thr)\n",
    "    exmap1_thr=np.zeros(shape=(1,224,224,3))\n",
    "    exmap1_thr[0,:,:,0]=img[0,:,:,0]*exmap1_msk\n",
    "    exmap1_thr[0,:,:,1]=img[0,:,:,1]*exmap1_msk\n",
    "    exmap1_thr[0,:,:,2]=img[0,:,:,2]*exmap1_msk\n",
    "    ex_predictions = model.predict(exmap1_thr)[0]\n",
    "    O1=ex_predictions[class_index]\n",
    "    etta=(Y-O1)/(Y+1e-100)\n",
    "    return (etta*(etta>0), 1*(etta<0), Y, O1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkisLKyaayDL"
   },
   "outputs": [],
   "source": [
    "val_generator.reset()\n",
    "drop_rate = 0.\n",
    "for _ in range(15):\n",
    "    image_batch,label_batch=val_generator.next()\n",
    "    for index in range(32):\n",
    "        prediction=model(image_batch)\n",
    "        explanation_map_SISE = SISE(np.expand_dims(image_batch[index], axis=0), model, layers=layers, class_index=np.argmax(prediction[index]), grad_thr=0.)\n",
    "        drop_rate += calculate_drop_increase(np.expand_dims(image_batch[index], axis=0), model, explanation_map_SISE, class_index=np.argmax(prediction[index]), frac=0.9)[0]\n",
    "drop_rate /= (15*32)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6RKtE7d0YAG2",
    "calsYefrYC1P",
    "-q-2qXovYJQ6",
    "Kvv6IX1-8n3O",
    "vHXAMFq68q8p",
    "zcPaIZw0-64V",
    "eFnbIyRflKIJ",
    "i42jHJAMlPxU",
    "UtaAc1QTlX_8",
    "_zJajjz3xtOY",
    "wngWZcQ92jSL"
   ],
   "name": "HMT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
